{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66f25cc-62e0-4c32-82b5-6d9d64aec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# load container dataset\n",
    "container_dataset = pd.read_csv(\"./ContainerData.csv\")\n",
    "\n",
    "# defining target and features\n",
    "target = [\"Priority\"]\n",
    "features = [\"Height\", \"Width\", \"Hue\", \"Times moved\"]\n",
    "\n",
    "selected_data = target + features\n",
    "container_dataset_subset = container_dataset[selected_data]\n",
    "\n",
    "# defining the test size\n",
    "train, test = train_test_split(container_dataset_subset, test_size=0.25)\n",
    "\n",
    "# instantiating encoder, so we can turn target (\"low\", \"high\") to binary value (\"0\", \"1\")\n",
    "encoder = LabelEncoder()\n",
    "# separating features from target (defined as X and Y axis)\n",
    "train_X = train[features]\n",
    "train_Y = train[target].to_numpy()\n",
    "\n",
    "test_X = test[features]\n",
    "test_Y = test[target].to_numpy()\n",
    "\n",
    "\n",
    "train_Y_encoded = encoder.fit_transform(train_Y.ravel())\n",
    "test_Y_encoded = encoder.transform(test_Y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e0020",
   "metadata": {},
   "source": [
    "This is the initial set up of our machine learning model:\n",
    "\n",
    "the goal is to correctly identify the priority of given containers to optimise sorting opeartions\n",
    "\n",
    "we've split the train and test data by 75% - 25%\n",
    "\n",
    "the target value is encoded to numerical value and mapped to allow the model to compute it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6064e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the ml model\n",
    "LR_model = LogisticRegression()\n",
    "\n",
    "# training and testing the model\n",
    "LR_model.fit(train_X, train_Y_encoded)\n",
    "predictions = LR_model.predict(test_X)\n",
    "\n",
    "decoded_predictions = encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804e62c",
   "metadata": {},
   "source": [
    "this is the initializtion of our machine learning model:\n",
    "\n",
    "we used the logistic regression model becasue it is capable of working with and return categorical values ( as opposed to linear regression which can only work with and retunrn numeric values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8aa110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value 0: high\n",
      "Predicted value 0: high\n",
      "Actual value 1: high\n",
      "Predicted value 1: high\n",
      "Actual value 2: low\n",
      "Predicted value 2: high\n",
      "Actual value 3: low\n",
      "Predicted value 3: high\n",
      "Actual value 4: low\n",
      "Predicted value 4: high\n",
      "Actual value 5: low\n",
      "Predicted value 5: high\n",
      "Actual value 6: high\n",
      "Predicted value 6: high\n",
      "Actual value 7: high\n",
      "Predicted value 7: low\n",
      "Actual value 8: high\n",
      "Predicted value 8: high\n",
      "Actual value 9: low\n",
      "Predicted value 9: high\n",
      "Actual value 10: low\n",
      "Predicted value 10: low\n",
      "Actual value 11: high\n",
      "Predicted value 11: low\n",
      "Actual value 12: low\n",
      "Predicted value 12: low\n",
      "Actual value 13: low\n",
      "Predicted value 13: high\n",
      "Actual value 14: high\n",
      "Predicted value 14: low\n",
      "Actual value 15: high\n",
      "Predicted value 15: low\n",
      "Actual value 16: low\n",
      "Predicted value 16: high\n",
      "Actual value 17: low\n",
      "Predicted value 17: high\n",
      "Actual value 18: high\n",
      "Predicted value 18: low\n",
      "Actual value 19: high\n",
      "Predicted value 19: low\n",
      "\n",
      "Accuracy: 0.79\n",
      "Precision (high): 0.81\n",
      "Precision (low): 0.77\n",
      "Recall (high): 0.75\n",
      "Recall (low): 0.83\n",
      "F1-Score (high): 0.78\n",
      "F1-Score (low): 0.80\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(20, len(train_Y), len(decoded_predictions))):\n",
    "    print(f\"Actual value {i}: {train_Y[i][0]}\\nPredicted value {i}: {decoded_predictions[i]}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(test_Y, decoded_predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
    "\n",
    "# the following metrics are used to offer more insights than accuracy alone, they are performed on both \"high\" and \"low\"\n",
    "# this metrics (along with accuracy) work on a % basis, so the closer to 1, or 100% (>0.75 being acceptable) the better\n",
    "\n",
    "# Precision\n",
    "precision_high = precision_score(test_Y, decoded_predictions, pos_label='high')\n",
    "print(f\"\"\n",
    "      f\"Precision (high): {precision_high:.2f}\")\n",
    "precision_low = precision_score(test_Y, decoded_predictions, pos_label='low')\n",
    "print(f\"Precision (low): {precision_low:.2f}\")\n",
    "\n",
    "# Recall\n",
    "recall_high = recall_score(test_Y, decoded_predictions, pos_label='high')\n",
    "print(f\"Recall (high): {recall_high:.2f}\")\n",
    "recall_low = recall_score(test_Y, decoded_predictions, pos_label='low')\n",
    "print(f\"Recall (low): {recall_low:.2f}\")\n",
    "\n",
    "# F1-Score\n",
    "f1_high = f1_score(test_Y, decoded_predictions, pos_label='high')\n",
    "print(f\"F1-Score (high): {f1_high:.2f}\")\n",
    "f1_low = f1_score(test_Y, decoded_predictions, pos_label='low')\n",
    "print(f\"F1-Score (low): {f1_low:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f803bf",
   "metadata": {},
   "source": [
    "The model predictions are evaluated using the following metrics, these work on a 0 to 1 basis wich means the closer to 1 the better the model performed\n",
    "(i.e. 0.75 which tranlsate to 75%):\n",
    "\n",
    "- Accuracy: measures the proportions of correctly identified instances out of the entire data pool\n",
    "    *(TruePositive + TrueNegatives / TotalInstances)*\n",
    "- Precision:  measuers the proportions of correctly predicted instances out of all the instances that where predicted positive\n",
    "    *(TruePositives / TruePositives + FalsePositives)*\n",
    "- Recall: measures the proportion of actual positive instances that the model correctly identified \n",
    "    *(TruePositives / True Positives + FalseNegatives)*\n",
    "- F1-Score: it's the harmonic mean of precision and recall, it serves to balance the two in scenarios where only one or the otehr would be missleading.\n",
    "*( 2 * Precision * Recal / Precision + Recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
